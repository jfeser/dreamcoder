The hyper parameters here are not consistent. A key thing we need to
do is make sure that we are always using the same hyper parameters, or
if we are not, we need a good reason for it. For example, the
structure penalty on text is larger than for the other domains, but
this is justifiable. And the top K for regular expressions is larger
than for the other domains but that is also justifiable. In contrast
the pseudocounts really should be the same everywhere.

LOGO:
Full model without batching:
     python launch.py -k  -z x1.32xlarge DreamLogo "python logo.py -t 7200 --structurePenalty 1.5 --pseudoCounts 30.0 --biasOptimal --contextual --split 0.5 --testingTimeout 3600"
Random shuffle (batches of 10), 720s: [DONE, solves 36/73 testing]
     python launch.py -k  -z r4.16xlarge LogoBatch "python logo.py -t 720  --structurePenalty 1.5 --pseudoCounts 30.0 --biasOptimal --contextual --split 0.5 --testingTimeout 3600  --storeTaskMetrics --taskReranker randomShuffle --taskBatchSize 10 -i 20  -R 1800 --reuseRecognition"
Random shuffle (batches of 10), 720s:  [DONE: solves 40/73 and ends up converging to a bad DSL]
     python launch.py -k  -z x1.32xlarge LogoBatch_24m "python logo.py -t 1440  --structurePenalty 1.5 --pseudoCounts 30.0 --biasOptimal --contextual --split 0.5 --testingTimeout 3600  --storeTaskMetrics --taskReranker randomShuffle --taskBatchSize 10 -i 30  -R 1800 "
Random shuffle (batches of 20), 30min: [DONE: solves 50/73 and still converges to a bad DSL]
     python launch.py -k  -z x1.32xlarge logo_batch_20_30m "python logo.py -t 1800  --structurePenalty 1.5 --pseudoCounts 30.0 --biasOptimal --contextual --split 0.5 --testingTimeout 600  --storeTaskMetrics --taskReranker randomShuffle --taskBatchSize 20 -i 30  -R 1800 "
Random shuffle (batches of 40), 60min: [PENDING]
            python launch.py -k  -z x1.32xlarge logo_batch_40_60m "python logo.py -t 3600  --structurePenalty 1.5 --pseudoCounts 30.0 --biasOptimal --contextual --split 0.5 --testingTimeout 600  --storeTaskMetrics --taskReranker randomShuffle --taskBatchSize 40 -i 20  -R 1800 "
     
TEXT:
Full model without batching:
     python launch.py -k  -z x1.32xlarge TextDream "python text.py  -i 6 -t 7200 --pseudoCounts 30 --testingTimeout 1800 --compressor ocaml --contextual --biasOptimal -l 5 --maximumFrontier 2"


Derby: (You can replace this checkpoint with a different one and it will run the Derby with it)
	python launch.py -k  -z c4.8xlarge --checkpoint experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.5_it=19_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle  batched_derby "python text.py --compete experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.5_it=19_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle"
	python launch.py -k  -z c4.8xlarge --checkpoint experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.5_it=20_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle  batched_derby_it20 "python text.py --compete experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.5_it=20_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle"

Baseline without batching, 3600s: text_baseline_3600s [Done: solves up to 80 tasks.]
	python launch.py  -k -z r4.16xlarge text_baseline_3600s "python text.py  -t 3600 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 7 -R 7200 --storeTaskMetrics --testingTimeout 3600 --biasOptimal --contextual --taskReranker default"

Baseline without batching, 7200: text_baseline_7200s	[Done: solves 87 tasks.]
	python launch.py  -k -z r4.16xlarge text_baseline_7200s "python text.py  -t 7200 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 7 -R 7200 --storeTaskMetrics --testingTimeout 7200 --biasOptimal --contextual --taskReranker default"

Random shuffle (batches of 10), 720s: text_random_shuffle_10_720s [DONE - solves 91.]
	python launch.py  -k -z r4.16xlarge text_random_shuffle_10_720s "python text.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --testingTimeout 720 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10"

Random shuffle (batches of 10), 720s, structure penalty: text_random_shuffle_10_720s_sp [Done - solves 56/108.]
	python launch.py  -k -z r4.16xlarge text_random_shuffle_10_720s_sp "python text.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 2.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --testingTimeout 720 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10"


Random shuffle (batches of 10), 720s, more dreams: text_random_shuffle_10_720s_r [Done - solves 59/108.]
	python launch.py  -k -z r4.16xlarge text_random_shuffle_10_720s_r "python text.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --testingTimeout 720 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10 -r 0.9"


Random shuffle_r: resuming (text_random_shuffle_10_720s_r) with more time: *text_resume_1440s
	python launch.py  -k --ssh_key openmind -z r4.16xlarge --checkpoint experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.9_it=20_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle text_resume_1440s "python text.py  -t 1440 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 31 -R 3600 --storeTaskMetrics --testingTimeout 1440 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10 -r 0.9 --resume experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.9_it=20_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle"

Random shuffle_r: resuming (text_random_shuffle_10_720s_r) with more time on just unsolved: *text_resume_unsolved_1440s
python launch.py  -k --ssh_key openmind -z r4.16xlarge --checkpoint experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.9_it=20_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle text_resume_unsolved_1440s "python text.py  -t 1440 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 31 -R 3600 --storeTaskMetrics --testingTimeout 1440 --biasOptimal --contextual --taskReranker unsolved --taskBatchSize 10 -r 0.9 --resume experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.9_it=20_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle"

Random shuffle_r: resuming (text_random_shuffle_10_720s_r) with more time on just unsolved: *text_resume_unsolved_2160s
python launch.py  -k --ssh_key openmind -z r4.16xlarge --checkpoint experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.9_it=20_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle text_resume_unsolved_2160s "python text.py  -t 2160 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 31 -R 3600 --storeTaskMetrics --testingTimeout 2160 --biasOptimal --contextual --taskReranker unsolved --taskBatchSize 10 -r 0.9 --resume experimentOutputs/text_aic=1.0_arity=3_BO=True_CO=True_ET=720_HR=0.9_it=20_MF=5_baseline=False_pc=30.0_RT=7200_RW=False_storeTask=True_L=1.0_batch=10_taskReranker=randomShuffle_K=2_topkNotMAP=False_rec=True_feat=LearnedFeatureExtractor.pickle"


Random shuffle (batches of 20), 1440s: text_random_shuffle_20_1440s [DONE - solves 56 tasks.]
	python launch.py  -k -z r4.16xlarge text_random_shuffle_20_1440s "python text.py  -t 1440 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 10 -R 7200 --storeTaskMetrics --testingTimeout 1440 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 20"

Random kNN (batches of 10), 720s: test_random_knn_10_720s [Done: solves up to 87 tasks.]
	python launch.py  -k -z r4.16xlarge test_random_knn_10_720s "python text.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --testingTimeout 720 --biasOptimal --contextual --taskReranker randomkNN --taskBatchSize 10"

Unsolved (ranked by entropy, batches of 10), 720s: text_unsolved_entropy_10_720s [Done - solves up to 91 tasks.]
	python launch.py  -k -z r4.16xlarge text_unsolved_entropy_10_720s "python text.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --testingTimeout 720 --biasOptimal --contextual --taskReranker unsolvedEntropy --taskBatchSize 10"

Curriculum (batch size 10), 720s: text_default_10_720s [Done - solves up to 91 tasks.]
	python launch.py  -k -z r4.16xlarge text_default_10_720s "python text.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --testingTimeout 720 --biasOptimal --contextual --taskReranker default --taskBatchSize 10"


LIST:
Full model without batching:
     python launch.py -k  -z x1.32xlarge ListDream "python list.py -t 7200 --split 0.5 --testingTimeout 600 --contextual --biasOptimal -i 6 --maximumFrontier 5 --pseudoCounts 10. --structurePenalty 2"

Full model without batching, 3600s timeout: list_baseline_3600 [DONE: 103/109.]
	python launch.py  -k -z x1.32xlarge list_baseline_3600 "python list.py  -t 3600 --compressor ocaml --pseudoCounts 10 --aic 1.0 --structurePenalty 2.0 --topK 2 --arity 3 --maximumFrontier 10 -i 7 -R 3600 --storeTaskMetrics --split 0.5 --testingTimeout 3600 --biasOptimal --contextual --taskReranker default"	

Full model without batching, 7200s timeout: list_baseline_7200s [DONE - Solves 109/109 tasks.]
	python launch.py  -k -z x1.32xlarge list_baseline_7200 "python list.py  -t 7200 --compressor ocaml --pseudoCounts 10 --aic 1.0 --structurePenalty 2.0 --topK 2 --arity 3 --maximumFrontier 10 -i 7 -R 3600 --storeTaskMetrics --split 0.5 --testingTimeout 7200 --biasOptimal --contextual --taskReranker default"

Random shuffle (batches of 10), 720s: list_random_shuffle_10_720s  [Done: Solves 101/109]
	python launch.py  -k -z r4.16xlarge list_random_shuffle_10_720s "python list.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --split 0.5 --testingTimeout 720 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10"

Random shuffle (batches of 10), structure penalty: list_random_shuffle_10_720s_sp [Done: solves 105/109.]
	python launch.py  -k -z r4.16xlarge list_random_shuffle_10_720s_sp "python list.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 2.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --split 0.5 --testingTimeout 720 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10"
Running for replication: *list_random_shuffle_10_720s_sp_v2
		python launch.py --ssh_key openmind -k -z r4.16xlarge list_random_shuffle_10_720s_sp_v2 "python list.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 2.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --split 0.5 --testingTimeout 720 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10"

Random shuffle (batches of 10), more dreams: list_random_shuffle_10_720s_r [Done: solves 104/109.]
	python launch.py  -k -z r4.16xlarge list_random_shuffle_10_720s_r "python list.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --split 0.5 --testingTimeout 720 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10 -r 0.9"

Random shuffle (batches of 20), 1440s: list_random_shuffle_20_1440s  [DONE: solves 102/109.]
	python launch.py  -k -z r4.16xlarge list_random_shuffle_20_1440s "python list.py  -t 1440 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 10 -R 7200 --storeTaskMetrics --split 0.5 --testingTimeout 1440 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10"


Random shuffle (batches of 10), structure penalty, retraining: list_random_shuffle_10_720s_sp_retrain [DONE: solves 85/109].
	python launch.py  -k -z r4.16xlarge list_random_shuffle
	e_10_720s_sp_retrain "python list.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 2.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 1800 --storeTaskMetrics --split 0.5 --testingTimeout 720 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10 --reuseRecognition"


Random kNN (batches of 10), 720s: list_random_knn_10_720s [Done - solves 84/109]
	python launch.py  -k -z r4.16xlarge list_random_knn_10_720s_catwong  "python list.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --split 0.5 --testingTimeout 720 --biasOptimal --contextual --taskReranker randomkNN --taskBatchSize 10"

Random kNN (batches of 10), regularized: list_random_knn_10_720s_reg [Done - solves 105/109.]
	python launch.py  -k -z r4.16xlarge list_random_knn_10_720s_reg  "python list.py  -t 720 --compressor ocaml --pseudoCounts 30 --aic 1.0 --structurePenalty 2.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 7200 --storeTaskMetrics --split 0.5 --testingTimeout 720 --biasOptimal --contextual --taskReranker randomkNN --taskBatchSize 10 -r 0.9"





TOWER:
Full model without batching: (Solves up to 51 tasks)
     python launch.py -k -z m4.16xlarge TowerDream5 "python tower.py -i 6 -t 300 --pseudoCounts 30 --tasks supervised --maximumFrontier 5 --compressor ocaml --biasOptimal --contextual --testingTimeout 600 --split 0.5 --pseudoCounts 10. --structurePenalty 1"

Random shuffle (batches of 5), 60s: tower_random_shuffle_5_60s [Done, solves 42/56]
	python launch.py -k -z m4.16xlarge tower_random_shuffle_5_60s "python tower.py -t 60 --compressor ocaml --pseudoCounts 30 --tasks supervised --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 300 --storeTaskMetrics --split 0.5 --testingTimeout 60 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 5"

Random shuffle (batches of 5), 60s: tower_random_shuffle_5_120s [Done, solves 45/56].
	python launch.py -k -z m4.16xlarge tower_random_shuffle_5_120s "python tower.py -t 120 --compressor ocaml --pseudoCounts 30 --tasks supervised --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 300 --storeTaskMetrics --split 0.5 --testingTimeout 120 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 5"

Random shuffle (batches of 10), 120s: tower_random_shuffle_10_120s [Done, solves 51/56]
	python launch.py -k -z m4.16xlarge tower_random_shuffle_10_120s "python tower.py -t 120 --compressor ocaml --pseudoCounts 30 --tasks supervised --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 10 -R 300 --storeTaskMetrics --split 0.5 --testingTimeout 120 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10"
			Re-run with new random shuffle (v2): solves 49/56.
		

Random shuffle (batches of 10), 120s. retraining: tower_random_shuffle_10_120s [12/18]
	python launch.py -k -z m4.16xlarge --ssh_key openmind tower_random_shuffle_10_120s "python tower.py -t 120 --compressor ocaml --pseudoCounts 30 --tasks supervised --aic 1.0 --structurePenalty 1.0 --topK 2 --arity 3 --maximumFrontier 5 -i 20 -R 300 --storeTaskMetrics --split 0.5 --testingTimeout 120 --biasOptimal --contextual --taskReranker randomShuffle --taskBatchSize 10 --reuseRecognition"

REGEX: Max: your stuff here
Best run so far (uses context free):
python launch.py -g -z "p3.16xlarge" "regex_gpu_contextfreeBO.95HR" "python regexes.py -t 3600 --testingTimeout 1800 --tasks new --maxTasks 256 --ll_cutoff bigram --split 0.5 -k 10 --biasOptimal -r .95"

Best contextual run:
python launch.py -g -z "p3.16xlarge" "regex_gpu_contextualBO.95HR" "python regexes.py -t 3600 --testingTimeout 1800 --tasks new --maxTasks 256 --ll_cutoff bigram --split 0.5 -k 10 --contextual --biasOptimal -r .95"

A task batching run
python launch.py -g -z "p3.16xlarge" "regex_gpu_batch_contextualBO.95HR" "python regexes.py -t 720 --testingTimeout 720 --tasks new --maxTasks 256 --ll_cutoff bigram --split 0.5 -k 10 --contextual --biasOptimal -r .95 --taskReranker randomShuffle --taskBatchSize 10"

task batchinng with rec model reuse:

python launch.py -g -z "p3.16xlarge" "regex_gpu_batch_reuserec_contextualBO.95HR" "python regexes.py -t 720 --testingTimeout 720 --tasks new --maxTasks 256 --ll_cutoff bigram --split 0.5 -k 10 --contextual --biasOptimal -r .95 --taskReranker randomShuffle --taskBatchSize 10 --reuseRecognition"
